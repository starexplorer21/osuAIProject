{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Yile Shen\n",
    "# 3/7/2024\n",
    "# Advanced Programming: AIML\n",
    "# Osu playing robot\n",
    "\n",
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# couple notes: i chose to switch to pytorch as I was more comfortable with it\n",
    "# and I needed to customize my model in a lot of ways, and I couldn't\n",
    "# adequately get tensorflow to work.\n",
    "\n",
    "# I also already had a really good setup for pytorch and I spent more time\n",
    "# tuning the gpu usage on tensorflow. Pytorch also saved WAY more memory overall.\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# print name\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "# i had a tensorflow version, but I couldn't get some things to work in it\n",
    "# so I switched to pytorch because I'm more comfortable with it and can do more.\n",
    "\n",
    "#process images here so I can change resolution whenever\n",
    "#\n",
    "# FOLDER_PATH = \"C:/Users/Yile0/PycharmProjects/osutime/frames/\"\n",
    "#\n",
    "# for i in range(14, 5379):\n",
    "#     img = cv2.imread(FOLDER_PATH + str(i)+\".png\")\n",
    "#     img = cv2.resize(img, (160, 120), interpolation=cv2.INTER_AREA)\n",
    "#     cv2.imwrite(FOLDER_PATH + str(i)+\".png\", img)\n",
    "# making a custom image dataset class for pytorch\n",
    "# originally had a custom dataset maker, but the dataloader is way better\n",
    "# and formats them better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x         y                                            frame 4  \\\n",
      "0  253.3333  256.4445  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "1  253.3333  256.0000  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "2  252.8889  256.0000  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "3  252.8889  256.0000  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "4  252.8889  256.0000  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "\n",
      "                                             frame 3  \\\n",
      "0  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "1  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "2  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "3  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "4  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "\n",
      "                                             frame 2  \\\n",
      "0  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "1  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "2  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "3  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "4  C:/Users/Yile0/PycharmProjects/osutime/frames/...   \n",
      "\n",
      "                                             frame 1  \n",
      "0  C:/Users/Yile0/PycharmProjects/osutime/frames/...  \n",
      "1  C:/Users/Yile0/PycharmProjects/osutime/frames/...  \n",
      "2  C:/Users/Yile0/PycharmProjects/osutime/frames/...  \n",
      "3  C:/Users/Yile0/PycharmProjects/osutime/frames/...  \n",
      "4  C:/Users/Yile0/PycharmProjects/osutime/frames/...  \n",
      "Index(['x', 'y', 'frame 4', 'frame 3', 'frame 2', 'frame 1'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1263it [00:17, 72.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 43\u001B[0m\n\u001B[0;32m     41\u001B[0m     processed_labels\u001B[38;5;241m.\u001B[39mappend([row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m], row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;66;03m# try to predict just on 1 frame for testing\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m     processed_data\u001B[38;5;241m.\u001B[39mappend(\u001B[43mprocess_img\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mframe 4\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mframe 3\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mframe 2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mframe 1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     46\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(processed_data, processed_labels, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "Cell \u001B[1;32mIn[2], line 22\u001B[0m, in \u001B[0;36mprocess_img\u001B[1;34m(paths)\u001B[0m\n\u001B[0;32m     20\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([transforms\u001B[38;5;241m.\u001B[39mToTensor()])\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m paths:\n\u001B[1;32m---> 22\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIMREAD_GRAYSCALE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;66;03m# 100 by 75 because slightly better quality\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m# over 80 by 60\u001B[39;00m\n\u001B[0;32m     25\u001B[0m     img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(img, (\u001B[38;5;241m120\u001B[39m, \u001B[38;5;241m68\u001B[39m), interpolation\u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39mINTER_AREA)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# compile dataset.\n",
    "dataset_path = \"C:/Users/Yile0/PycharmProjects/osutime/map1_data.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)\n",
    "# small data for changing, basically just for trialing new changes.\n",
    "small_data = sklearn.utils.resample(data, n_samples= 1000)\n",
    "\n",
    "# frame 4 is the latest/ most recent.\n",
    "\n",
    "#originally these were one piece, changed for the dataloader to function\n",
    "processed_data = []\n",
    "processed_labels = []\n",
    "\n",
    "\n",
    "def process_img(paths):\n",
    "    # I had another self-made thing here that I decided to replace with premade functions\n",
    "    images = []\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    for path in paths:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        # 100 by 75 because slightly better quality\n",
    "        # over 80 by 60\n",
    "        img = cv2.resize(img, (120, 68), interpolation=cv2.INTER_AREA)\n",
    "        img_normalized = cv2.normalize(img, None, 0, 1.0,\n",
    "                                       cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        images.append(transform(img_normalized))\n",
    "    out = torch.stack(images)\n",
    "    # i played with trying to reshape to 120 16, but I came back\n",
    "    # to this resolution because it was just so much better and faster\n",
    "    # with regards to my training speed.\n",
    "    out = out.reshape(len(paths),68,120)\n",
    "    # played with preloading here and loading later, seems like loading later is better.\n",
    "    # img = torch.from_numpy(img)\n",
    "    return out\n",
    "\n",
    "\n",
    "for index, row in tqdm(data.iterrows()):\n",
    "    # trying without normalization.\n",
    "    processed_labels.append([row['x'], row['y']])\n",
    "    # try to predict just on 1 frame for testing\n",
    "    processed_data.append(process_img([row['frame 4'],row['frame 3'],row['frame 2'],row['frame 1']]))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data, processed_labels, test_size=0.1, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T04:24:23.348119900Z",
     "start_time": "2024-12-17T04:24:05.591520800Z"
    }
   },
   "id": "e4982317ce4ad637"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, imageTransform=None, num_workers=0):\n",
    "        self.imageTransform = imageTransform\n",
    "        self.num_workers = num_workers\n",
    "        self.imgs = images\n",
    "        self.targets = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.imgs[idx]\n",
    "        target = self.targets[idx]\n",
    "        label = torch.Tensor(target)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-17T04:24:23.349127600Z"
    }
   },
   "id": "3238d9ace87644e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating a CNN class\n",
    "# conv neural net combined was bad, this iteration separates them\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        # adjusted the first pooling to be 4 instead.\n",
    "        # tried second pooling to be 4 too\n",
    "\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=4, out_channels=512, kernel_size=4)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4)\n",
    "        self.max_pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=512, out_channels=64, kernel_size=4)\n",
    "        self.max_pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        # originally tried relu layers, but wanted something non-linear\n",
    "        # went back because elu wasn't doing better\n",
    "        # had 3 layers to begin with, then tried 4, then tried 7\n",
    "        # I one off tried 13 but it didn't fit.=\n",
    "        self.fc2 = nn.Linear(128,128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 16)\n",
    "        self.fc7 = nn.Linear(16, 1)\n",
    "        # self.relu7 = nn.ReLU()\n",
    "        # self.fc8 = nn.Linear(75, 1)\n",
    "        # self.relu8 = nn.ReLU()\n",
    "        # self.fc9 = nn.Linear(25, 1)\n",
    "        # self.relu9 = nn.ReLU()\n",
    "        # self.fc10 = nn.Linear(50, 1)\n",
    "    # Progresses data across layers\n",
    "    def forward(self, input):\n",
    "        out_x = self.conv_layer1(input)\n",
    "        out_x = self.relu(out_x)\n",
    "        out_x = self.max_pool1(out_x)\n",
    "        out_x = self.conv_layer2(out_x)\n",
    "        out_x = self.relu(out_x)\n",
    "        out_x = self.max_pool2(out_x)\n",
    "\n",
    "        out_x = self.conv_layer3(out_x)\n",
    "        out_x = self.relu(out_x)\n",
    "        out_x = self.max_pool3(out_x)\n",
    "        out_x = self.conv_layer4(out_x)\n",
    "        out_x = self.relu(out_x)\n",
    "        out_x = self.max_pool4(out_x)\n",
    "\n",
    "        out_x = out_x.reshape(out_x.size(0), -1)\n",
    "        \n",
    "        out_x = self.fc1(out_x)\n",
    "        out_x = self.sigmoid(out_x)\n",
    "        out_x = self.fc2(out_x)\n",
    "        out_x = self.sigmoid(out_x)\n",
    "        out_x = self.fc3(out_x)\n",
    "        out_x = self.sigmoid(out_x)\n",
    "        # out_x = self.relu(out_x)\n",
    "        # out_x = self.relu(out_x)\n",
    "        # out_x = self.relu(out_x)\n",
    "\n",
    "        return out_x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T04:24:23.351125Z",
     "start_time": "2024-12-17T04:24:23.350126Z"
    }
   },
   "id": "687719ad30eaa4b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "# tried batch sizes of 32 and 128 as well, but this was best\n",
    "# 128 had better cuda utilization but didn't boost speed too much.\n",
    "# decided it was more worth it to have better accuracy because 128 could\n",
    "# introduce inaccuracies.\n",
    "# after adding a few new layers 64 wasn't enough to have fast epochs\n",
    "# so I decided to move to 128.\n",
    "# accidentally tried batch size of 1, was way too inefficient\n",
    "batch_size = 80\n",
    "# originally learning rate was 0.001, but im making it learn longer and slower.\n",
    "# makes me wonder if my original idea would have worked, but now it's too late to fix it.\n",
    "# 0.001 basically didn't learn. I trained for somwhere around 500 epochs and loss basiclly didn't change\n",
    "# from now on, I ran some 20 epoch experiments.\n",
    "# 0.0001 was learning a lot to start, but loss seems to cycle between 0.10 and 0.13 or so\n",
    "\n",
    "# 0.00001 had loss settle at around 0.28/0.3, which is maybe due to the lack of time it had to train.\n",
    "# loss was generally going down even at 50 epochs, can't tell without a longer experiment.\n",
    "# i'm going to keep it at this and train for 100 and see what happens.\n",
    "# doesn't seem to improve past loss = 0.11\n",
    "\n",
    "# running a 400 epoch experiment with learning rate 0.000001\n",
    "learning_rate = 0.00001\n",
    "# ran a few experiments on 20 epochs to see if it would learn.\n",
    "num_epochs = 25\n",
    "device = \"cuda\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-17T04:24:23.351125Z"
    }
   },
   "id": "d6a7c45f22aa9850"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = ImageDataset(X_test, y_train)\n",
    "test = ImageDataset(X_test, y_test)\n",
    "\n",
    "# added workers to speedup epoch time.\n",
    "# 3 is the max tolerable it seems.\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# model = ConvNeuralNet(2, train_data.shape[0])\n",
    "\n",
    "# Set Loss function with criterion\n",
    "\n",
    "model_x = ConvNeuralNet(2)\n",
    "model_x.cuda(device)\n",
    "# adam is just better, tried other optimizers like sgd though\n",
    "optimizer_x = torch.optim.Adam(model_x.parameters(), lr=learning_rate)\n",
    "\n",
    "model_y = ConvNeuralNet(2)\n",
    "model_y.cuda(device)\n",
    "# adam is just better, tried other optimizers like sgd though\n",
    "\n",
    "optimizer_y = torch.optim.Adam(model_y.parameters(), lr=learning_rate)\n",
    "# MSE loss instead of L1, which is squared loss vs linear loss.\n",
    "# Huber over both, has the benefits of both.\n",
    "criterion = nn.MSELoss()\n",
    "epoch_start = 0\n",
    "\n",
    "\n",
    "epoch_start = 0\n",
    "# added code that allows it to train again from a checkpoint\n",
    "# it lets me train in chunks over time.\n",
    "# checkpoint = torch.load('model.pth')\n",
    "# model_x.load_state_dict(checkpoint['model_x_state_dict'])\n",
    "# optimizer_x.load_state_dict(checkpoint['optimizer_x_state_dict'])\n",
    "# model_y.load_state_dict(checkpoint['model_y_state_dict'])\n",
    "# optimizer_y.load_state_dict(checkpoint['optimizer_y_state_dict'])\n",
    "# epoch_start = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "\n",
    "total_step = len(processed_data)\n",
    "\n",
    "model_x.train()\n",
    "model_y.train()\n",
    "\n",
    "losses_x = []\n",
    "losses_y = []\n",
    "losses_val_x = []\n",
    "losses_val_y = []\n",
    "\n",
    "lr_y = []\n",
    "lr_x = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-17T04:24:23.352124Z"
    }
   },
   "id": "e63d58e767afaafd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "def main():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    for epoch in range(epoch_start, num_epochs):\n",
    "        start = time.time()\n",
    "        model_x.train()\n",
    "        model_y.train()\n",
    "        # Load in the data in batches using the train_loader object\n",
    "        for i, (images, labels) in enumerate(tqdm(data_loader, desc = \"Epoch \" + str(epoch+1), miniters=10)):\n",
    "            images = images.cuda(device)\n",
    "            # Move tensors to the configured device\n",
    "            # images already got loaded on\n",
    "            # images = images.to(device)\n",
    "            labels = labels.cuda(device)\n",
    "            x_labels = labels[:, 0].unsqueeze(1)\n",
    "            x_labels.requires_grad = True\n",
    "            x_labels = x_labels.cuda(device)\n",
    "            y_labels = labels[:, 1].unsqueeze(1)\n",
    "            y_labels.requires_grad = True\n",
    "            y_labels = y_labels.cuda(device)\n",
    "            # Forward pass\n",
    "            output_x = model_x(images) * 512\n",
    "            loss_x = criterion(output_x, x_labels)\n",
    "            output_y = model_y(images) * 384\n",
    "            loss_y = criterion(output_y, y_labels)\n",
    "            # Backward and optimize\n",
    "            optimizer_y.zero_grad()\n",
    "            optimizer_x.zero_grad()\n",
    "            # had tried to combined, but now i'm just completely\n",
    "            # separating the two models.\n",
    "            loss_x.backward()\n",
    "            loss_y.backward()\n",
    "            optimizer_y.step()\n",
    "            optimizer_x.step()\n",
    "        # added checkpoint saver\n",
    "        if (epoch + 1) % 6 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_x_state_dict': model_x.state_dict(),\n",
    "                'optimizer_x_state_dict': optimizer_x.state_dict(),\n",
    "                'model_y_state_dict': model_y.state_dict(),\n",
    "                'optimizer_y_state_dict': optimizer_y.state_dict(),\n",
    "                'loss': criterion,\n",
    "            }, \"model.pth\")\n",
    "        model_x.eval()\n",
    "        model_y.eval()\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            images = images.to(device)\n",
    "            # Move tensors to the configured device\n",
    "            # images already got loaded on\n",
    "            # images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            x_labels = labels[:, 0].unsqueeze(1)\n",
    "            y_labels = labels[:, 1].unsqueeze(1)\n",
    "            # Forward pass\n",
    "            output_x = model_x(images) * 512\n",
    "            loss_x_valid = criterion(output_x, x_labels)\n",
    "            output_y = model_y(images) * 384\n",
    "            loss_y_valid = criterion(output_y, y_labels)\n",
    "\n",
    "        print('x val')\n",
    "        print(x_labels)\n",
    "        print(output_x)\n",
    "        print('y val')\n",
    "        print(y_labels)\n",
    "        print(output_y)\n",
    "\n",
    "        # step lr scheduler\n",
    "        # add so I can graph later\n",
    "        losses_x.append(loss_x.item())\n",
    "        losses_y.append(loss_y.item())\n",
    "        losses_val_x.append(loss_x_valid.item())\n",
    "        losses_val_y.append(loss_y_valid.item())\n",
    "        print('validate Loss_X: {:.10f}, validate Loss_y : {:.10f}'.format( loss_x_valid.item(), loss_y_valid.item()))\n",
    "\n",
    "        end = time.time()\n",
    "        print('Epoch [{}/{}], Loss1: {:.10f}, Loss2 : {:.4f} Time: {:.10f}'.format(epoch + 1, num_epochs, loss_x.item(), loss_y.item(), end-start))\n",
    "\n",
    "    torch.save({\n",
    "                    'epoch': num_epochs,\n",
    "                    'model_x_state_dict': model_x.state_dict(),\n",
    "                    'optimizer_x_state_dict': optimizer_x.state_dict(),\n",
    "                    'model_y_state_dict': model_y.state_dict(),\n",
    "                    'optimizer_y_state_dict': optimizer_y.state_dict(),\n",
    "                    'loss': criterion,\n",
    "                }, \"model.pth\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-17T04:24:23.353123700Z"
    }
   },
   "id": "23e84f7858f74ce0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(list(range(epoch_start, num_epochs)), losses_x)\n",
    "plt.plot(list(range(epoch_start, num_epochs)), losses_val_x, '-.')\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title('x_losses')\n",
    "plt.ylim(0, 0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(epoch_start, num_epochs)), losses_y)\n",
    "plt.plot(list(range(epoch_start, num_epochs)), losses_val_y, '-.')\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title('y losses')\n",
    "plt.ylim(0, 0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(epoch_start, num_epochs)), lr_x)\n",
    "plt.plot(list(range(epoch_start, num_epochs)), lr_y, '-.')\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title('learning rate')\n",
    "plt.ylim(0, 0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for i, (labels, images) in enumerate(processed_data):\n",
    "#         images = images.reshape((1, 4, 60, 80))\n",
    "#         images = images.to(device)\n",
    "#         labels = torch.tensor(labels, dtype=torch.float32)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         print([labels[0], labels[1]], [outputs[0], outputs[1]])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-17T04:24:23.354124200Z"
    }
   },
   "id": "1e3c3146b1737bfb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T04:24:23.356123400Z",
     "start_time": "2024-12-17T04:24:23.355124100Z"
    }
   },
   "id": "4aae66415c44aba2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
